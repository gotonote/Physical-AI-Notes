# 计算机视觉基础

本章介绍计算机视觉的基础知识，包括图像处理、特征提取、经典算法等，为后续的感知技术学习打下基础。

## 目录

- [1. 图像基础](#1-图像基础)
- [2. 图像预处理](#2-图像预处理)
- [3. 特征提取与描述](#3-特征提取与描述)
- [4. 图像分类与检测](#4-图像分类与检测)
- [5. 语义分割](#5-语义分割)
- [6. 目标跟踪](#6-目标跟踪)

---

## 1. 图像基础

### 1.1 数字图像表示

数字图像是由像素组成的二维矩阵，通常使用数组表示：

```
图像 I(x, y) 表示在坐标 (x, y) 处的像素值
```

- **灰度图像**：单通道，像素值范围 0-255（8bit）
- **RGB图像**：三通道，分别表示红、绿、蓝分量
- **深度图像**：每个像素表示到物体的距离

### 1.2 相机模型

#### 针孔相机模型

相机将3D世界坐标投影到2D图像平面：

$$
\begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = \frac{1}{Z} \begin{bmatrix} f & 0 & c_x \\ 0 & f & c_y \\ 0 & 0 & 1 \end{bmatrix} \begin{bmatrix} X \\ Y \\ Z \end{bmatrix}
$$

其中：
- $(X, Y, Z)$：3D世界坐标
- $(u, v)$：2D图像坐标
- $f$：焦距
- $(c_x, c_y)$：主点坐标

#### 内参矩阵

$$
K = \begin{bmatrix} f_x & 0 & c_x \\ 0 & f_y & c_y \\ 0 & 0 & 1 \end{bmatrix}
$$

### 1.3 坐标系变换

| 坐标系 | 描述 |
|--------|------|
| 世界坐标系 | 3D空间的绝对参考系 |
| 相机坐标系 | 以相机为中心的坐标系 |
| 图像坐标系 | 2D图像平面坐标系 |
| 像素坐标系 | 图像的离散像素坐标 |

---

## 2. 图像预处理

### 2.1 灰度转换

```python
import cv2
import numpy as np

def rgb_to_gray(image):
    """RGB转灰度图 - 使用加权平均法"""
    # 标准权重: Y = 0.299*R + 0.587*G + 0.114*B
    gray = 0.299 * image[:, :, 0] + 0.587 * image[:, :, 1] + 0.114 * image[:, :, 2]
    return gray.astype(np.uint8)

# 使用OpenCV
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
```

### 2.2 图像滤波

#### 高斯滤波

用于去除噪声和平滑图像：

```python
def gaussian_filter(image, kernel_size=5, sigma=1.0):
    """高斯滤波"""
    return cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)
```

#### 中值滤波

对椒盐噪声效果显著：

```python
def median_filter(image, kernel_size=5):
    """中值滤波"""
    return cv2.medianBlur(image, kernel_size)
```

#### 双边滤波

保持边缘的同时去除噪声：

```python
def bilateral_filter(image, d=9, sigma_color=75, sigma_space=75):
    """双边滤波"""
    return cv2.bilateralFilter(image, d, sigma_color, sigma_space)
```

### 2.3 图像增强

#### 直方图均衡化

增强图像对比度：

```python
def histogram_equalization(gray_image):
    """直方图均衡化"""
    # 全局均衡化
    equ = cv2.equalizeHist(gray_image)
    
    # CLAHE (对比度受限自适应直方图均衡化)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl1 = clahe.apply(gray_image)
    return cl1
```

---

## 3. 特征提取与描述

### 3.1 角点检测

#### Harris角点检测

```python
def harris_corner_detection(gray_image, threshold=0.01):
    """Harris角点检测"""
    # 转换为float32
    gray = np.float32(gray_image)
    
    # 计算Harris响应
    dst = cv2.cornerHarris(gray, blockSize=2, ksize=3, k=0.04)
    
    # 阈值化
    dst = cv2.dilate(dst, None)
    corners = dst > threshold * dst.max()
    
    return corners
```

#### Shi-Tomasi角点检测

```python
def shi_tomasi_detection(gray_image, max_corners=100, quality_level=0.01):
    """Shi-Tomasi角点检测"""
    corners = cv2.goodFeaturesToTrack(gray_image, 
                                       max_corners, 
                                       quality_level, 
                                       minDistance=10)
    return corners
```

### 3.2 SIFT特征

尺度不变特征变换（Scale-Invariant Feature Transform）：

```python
def sift_features(image):
    """SIFT特征提取"""
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(image, None)
    return keypoints, descriptors
```

**SIFT算法特点**：
- 尺度不变性
- 旋转不变性
- 对光照变化鲁棒

### 3.3 ORB特征

Oriented FAST and Rotated BRIEF - 实时应用的理想选择：

```python
def orb_features(image, n_features=1000):
    """ORB特征提取"""
    orb = cv2.ORB_create(nfeatures=n_features)
    keypoints, descriptors = orb.detectAndCompute(image, None)
    return keypoints, descriptors
```

**ORB算法特点**：
- 计算速度快
- 内存占用低
- 旋转不变性

### 3.4 特征匹配

```python
def feature_matching(image1, image2, method='bf'):
    """特征匹配"""
    # 提取特征
    kp1, des1 = orb_features(image1)
    kp2, des2 = orb_features(image2)
    
    # BFMatcher (Brute Force)
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(des1, des2)
    
    # 按距离排序
    matches = sorted(matches, key=lambda x: x.distance)
    
    return kp1, kp2, matches
```

---

## 4. 图像分类与检测

### 4.1 传统方法

#### HOG特征 + SVM

```python
def hog_svm_classification(image):
    """HOG特征 + SVM分类"""
    # 提取HOG特征
    win_size = (64, 64)
    cell_size = (8, 8)
    block_size = (16, 16)
    block_stride = (8, 8)
    num_bins = 9
    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, 
                           cell_size, num_bins)
    features = hog.compute(image)
    
    # 分类 (需要预先训练的SVM)
    # prediction = svm.predict(features)
    return features
```

### 4.2 深度学习方法

#### CNN图像分类

```python
import torch
import torch.nn as nn

class SimpleCNN(nn.Module):
    def __init__(self, num_classes=1000):
        super(SimpleCNN, self).__init__()
        self.features = nn.Sequential(
            # Conv Block 1
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # Conv Block 2
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # Conv Block 3
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
2d(kernel_size=2, stride            nn.MaxPool=2),
        )
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(256, num_classes)
        )
        
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x
```

#### YOLO目标检测

```python
# 使用YOLOv5进行目标检测
def yolo_detection(image_path, model_path='yolov5s.pt'):
    """YOLO目标检测"""
    model = torch.hub.load('ultralytics/yolov5', 'yolov5s')
    
    # 检测
    results = model(image_path)
    
    # 解析结果
    detections = results.pandas().xyxy[0]
    return detections
```

---

## 5. 语义分割

### 5.1 FCN (Fully Convolutional Network)

```python
class FCN8s(nn.Module):
    def __init__(self, num_classes=21):
        super(FCN8s, self).__init__()
        # 使用VGG作为backbone
        vgg = models.vgg16(pretrained=True)
        
        # Encoder
        self.pool3 = vgg.features[:17]  # 1/8
        self.pool4 = vgg.features[17:24]  # 1/16
        self.pool5 = vgg.features[24:]  # 1/32
        
        # Decoder
        self.conv6 = nn.Conv2d(512, 4096, 1)
        self.conv7 = nn.Conv2d(4096, 4096, 1)
        self.score_fr = nn.Conv2d(4096, num_classes, 1)
        
        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, 4, stride=2)
        self.upscore8 = nn.ConvTranspose2d(num_classes, num_classes, 16, stride=8)
```

### 5.2 DeepLab系列

- **DeepLabv3+**：使用ASPP（Atrous Spatial Pyramid Pooling）和编码器-解码器结构
- **特点**：多尺度空洞卷积、强大的上下文信息

---

## 6. 目标跟踪

### 6.1 卡尔曼滤波跟踪

```python
class KalmanTracker:
    def __init__(self):
        self.kf = KalmanFilter(dim_x=4, dim_z=2)
        self.kf.F = np.array([[1, 0, 1, 0],
                              [0, 1, 0, 1],
                              [0, 0, 1, 0],
                              [0, 0, 0, 1]])  # 状态转移矩阵
        self.kf.H = np.array([[1, 0, 0, 0],
                              [0, 1, 0, 0]])  # 观测矩阵
        self.kf.P *= 10
        self.kf.R *= 0.1
        
    def predict(self):
        return self.kf.predict()
    
    def update(self, measurement):
        return self.kf.update(measurement)
```

### 6.2 SORT跟踪

Simple Online and Realtime Tracking：

```python
def sort_tracking(detections, iou_threshold=0.3):
    """SORT目标跟踪"""
    # 1. 预测：使用卡尔曼滤波预测所有跟踪框的位置
    # 2. 匹配：使用匈牙利算法匹配检测框和跟踪框
    # 3. 更新：更新匹配的跟踪框状态
    # 4. 管理：添加新跟踪、移除丢失的跟踪
    pass
```

---

## 参考文献

1. Lowe, D. G. (2004). Distinctive Image Features from Scale-Invariant Keypoints. IJCV.
2. Rublee, E., et al. (2011). ORB: An efficient alternative to SIFT or SURF. ICCV.
3. Redmon, J., et al. (2016). You Only Look Once: Unified, Real-Time Object Detection. CVPR.
4. Long, J., et al. (2015). Fully Convolutional Networks for Semantic Segmentation. CVPR.

---

*本章节持续更新中...*
