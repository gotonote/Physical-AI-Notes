# 05 模仿学习

模仿学习通过模仿专家行为来获取技能，是机器人学习的重要范式。本章介绍行为克隆、逆强化学习、扩散策略等核心技术。

## 目录

- [1. 行为克隆](./Behavior_Cloning.md)
  - 监督学习方法
  - 正则化技术
- [2. 逆强化学习](./Inverse_Reinforcement_Learning.md)
  - 最大熵IRL
  - GAIL
- [3. 扩散策略](./Diffusion_Policy.md)
  - 条件扩散模型
  - 视觉运动策略
- [4. DAgger](./DAgger.md)
  - 迭代式专家聚合
  - 选择性标注

---

## 核心概念

### 模仿学习 vs 强化学习

| 方面 | 强化学习 | 模仿学习 |
|------|----------|----------|
| 监督信号 | 稀疏奖励 | 专家演示 |
| 样本效率 | 低 | 高 |
| 探索 | 需要 | 不需要 |
| 奖励设计 | 需要 | 不需要 |

### 方法对比

```
┌─────────────────────────────────────────┐
│            模仿学习方法                │
├─────────────────────────────────────────┤
│  BC        │ 直接监督学习，简单        │
│            │ 分布偏移问题              │
├────────────┼──────────────────────────┤
│  IRL       │ 推断奖励函数              │
│            │ 计算复杂                 │
├────────────┼──────────────────────────┤
│  Diffusion │ 多模态策略               │
│            │ 生成式方法               │
├────────────┼──────────────────────────┤
│  DAgger    │ 纠正分布偏移              │
│            │ 需要专家在线             │
└─────────────────────────────────────────┘
```

---

## 重要论文

1. **DAgger** (2011): Ross et al. - A reduction of imitation learning
2. **GAIL** (2016): Ho & Ermon - Generative Adversarial Imitation Learning
3. **Diffusion Policy** (2023): Chi et al. - Visuomotor Policy Learning via Action Diffusion

---

## 实践框架

### 数据集

| 数据集 | 描述 | 场景 |
|--------|------|------|
| DAML | 机器人操作数据集 | 抓取、放置 |
| RoboNet | 多机器人数据集 | 多任务 |
| Bridge Data | 互联网机器人数据 | 跨泛化 |

### 训练技巧

1. **数据增强**: 添加噪声提高鲁棒性
2. **课程学习**: 从简单到复杂
3. **专家混合**: BC + RL

---

*本章节持续更新中...*
