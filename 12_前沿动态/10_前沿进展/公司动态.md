# 公司动态

Physical AI领域的公司发展和产品发布。

## 目录

- [1. 科技巨头](#1-科技巨头)
- [2. 机器人公司](#2-机器人公司)
- [3. 自动驾驶](#3-自动驾驶)
- [4. 初创公司](#4-初创公司)
- [5. 最新产品对比](#5-最新产品对比)

---

## 1. 科技巨头

### 1.1 Google DeepMind

- **RT系列**: RT-1, RT-2, RT-3, RT-4
- **Gemini Robotics**: 多模态大模型
- **SIMA**: 通用代理

### 1.2 NVIDIA

- **Isaac Sim**: 仿真平台
- **GR00T**: 人形机器人基础模型
- **Cosmos**: 世界模型

### 1.3 Isaac Sim 代码示例

```python
import omni.usd
from pxr import Usd, UsdGeom, Gf

class IsaacSimSetup:
    """NVIDIA Isaac Sim 环境配置"""
    
    def __init__(self):
        self.stage = omni.usd.get_context().get_stage()
        
    def create_robot(self, robot_usd_path, prim_path="/World/Robot"):
        """加载机器人USD"""
        # 加载机器人USD asset
        UsdGeom.ImportPayloadOrReference(
            self.stage, 
            robot_usd_path, 
            prim_path
        )
        
        # 获取robot prim
        self.robot_prim = self.stage.GetPrimAtPath(prim_path)
        return self.robot_prim
    
    def setup_dof_properties(self, robot_prim):
        """配置关节属性"""
        from omni.isaac.core.robots import Robot
        
        # 设置关节控制模式
        robot = Robot(robot_prim)
        
        # 配置关节属性
        robot.set_joint_stiffness({
            'joint1': 1000.0,
            'joint2': 800.0,
            'joint3': 600.0,
        })
        
        robot.set_joint_damping({
            'joint1': 50.0,
            'joint2': 40.0,
            'joint3': 30.0,
        })
        
        return robot
    
    def add_camera(self, camera_path, position, rotation):
        """添加相机传感器"""
        camera_prim = UsdGeom.Camera.Define(self.stage, camera_path)
        
        # 设置相机属性
        camera_prim.CreateFocalLengthAttr(50.0)
        camera_prim.CreateFocusDistanceAttr(1000.0)
        camera_prim.CreateApertureAttr(5.6)
        
        # 设置位置
        xform = UsdGeom.Xformable(camera_prim)
        xform.AddTranslateOp().Set(Gf.Vec3d(*position))
        xform.AddRotateXYZOp().Set(Gf.Vec3d(*rotation))
        
        return camera_prim
    
    def run_simulation(self, num_steps=1000):
        """运行仿真"""
        from omni.isaac.core import SimulationContext
        
        sim = SimulationContext()
        sim.play()
        
        for _ in range(num_steps):
            sim.step()
            
        return sim.get_physics_dt()
```

### 1.4 OpenAI

- **机器人研究团队**: 灵巧手
- **视频理解**: Sora应用

---

## 2. 机器人公司

### 2.1 Boston Dynamics

- Atlas电动版
- Spot持续迭代

### 2.2 Figure AI

- Figure 01/02
- 与OpenAI合作

### 2.3 Unitree

- G1人形机器人
- 价格亲民化

### 2.4 Unitree G1 控制示例

```python
import numpy as np
import sdk.units as units

class UnitreeG1Controller:
    """Unitree G1 人形机器人控制器"""
    
    def __init__(self):
        # 关节配置
        self.joint_names = [
            'left_hip_pitch', 'left_hip_roll', 'left_hip_yaw',
            'left_knee', 'right_hip_pitch', 'right_hip_roll',
            'right_hip_yaw', 'right_knee',
            'torso', 'left_shoulder_pitch', 'left_shoulder_roll',
            'left_elbow', 'right_shoulder_pitch', 'right_shoulder_roll',
            'right_elbow'
        ]
        
        # 默认关节角度 (弧度)
        self.default_pose = {
            'left_hip_pitch': -0.1,
            'left_hip_roll': 0.0,
            'left_hip_yaw': 0.0,
            'left_knee': 0.2,
            'right_hip_pitch': -0.1,
            'right_hip_roll': 0.0,
            'right_hip_yaw': 0.0,
            'right_knee': 0.2,
            'torso': 0.0,
            'left_shoulder_pitch': 0.3,
            'left_shoulder_roll': 0.0,
            'left_elbow': -0.5,
            'right_shoulder_pitch': 0.3,
            'right_shoulder_roll': 0.0,
            'right_elbow': -0.5,
        }
        
    def forward_kinematics(self, joint_angles):
        """正向运动学 - 计算末端位置"""
        # 简化的运动学计算
        # 实际需要使用完整的DH参数
        hip_height = 0.65  # 髋关节高度
        leg_length = 0.65  # 腿长
        
        # 计算脚部位置
        hip_pitch = joint_angles['left_hip_pitch']
        knee = joint_angles['left_knee']
        
        # 简化模型
        x = 0
        y = 0
        z = hip_height - leg_length * np.cos(hip_pitch + knee)
        
        return np.array([x, y, z])
    
    def inverse_kinematics(self, target_pos, leg='left'):
        """逆向运动学 - 计算关节角度"""
        hip_height = 0.65
        thigh_len = 0.4
        calf_len = 0.4
        
        x, y, z = target_pos
        
        # 计算髋膝关节角度
        d = np.sqrt(x**2 + (z - hip_height)**2)
        
        # 余弦定理
        cos_knee = (thigh_len**2 + calf_len**2 - d**2) / (2 * thigh_len * calf_len)
        knee_angle = np.arccos(np.clip(cos_knee, -1, 1))
        
        # 髋关节角度
        alpha = np.arctan2(z - hip_height, x)
        beta = np.arccos((thigh_len**2 + d**2 - calf_len**2) / (2 * thigh_len * d))
        
        hip_pitch = alpha + beta
        
        return {
            f'{leg}_hip_pitch': -hip_pitch,
            f'{leg}_knee': np.pi - knee_angle,
        }
    
    def balance_control(self, imu_data, contact_states):
        """平衡控制"""
        roll, pitch, yaw = imu_data['rpy']
        
        # PD控制
        kp = 50.0
        kd = 5.0
        
        # 目标角度
        target_roll = 0.0
        target_pitch = 0.0
        
        # 计算补偿
        compensation = {
            'left_hip_roll': kp * (roll - target_roll),
            'right_hip_roll': -kp * (roll - target_roll),
            'left_hip_pitch': kp * (pitch - target_pitch),
            'right_hip_pitch': kp * (pitch - target_pitch),
        }
        
        return compensation
```

---

## 3. 自动驾驶

| 公司 | 进展 | 级别 |
|------|------|------|
| Waymo | 商业运营 | L4 |
| Cruise | 暂停运营 | L4 |
| Tesla | FSD v12 | L2+ |
| 中国厂商 | 多地试点 | L3/L4 |

### 3.1 自动驾驶架构示例

```python
class AutonomousDrivingSystem:
    """自动驾驶系统架构"""
    
    def __init__(self):
        # 感知模块
        self.perception = PerceptionModule()
        
        # 定位模块
        self.localization = LocalizationModule()
        
        # 预测模块
        self.prediction = PredictionModule()
        
        # 规划模块
        self.planning = PlanningModule()
        
        # 控制模块
        self.control = ControlModule()
        
    def perception_step(self, sensor_data):
        """感知步骤"""
        # 相机检测
        objects = self.perception.detect_objects(sensor_data['cameras'])
        
        # 雷达检测
        radar_objects = self.perception.detect_radar(sensor_data['radar'])
        
        # 激光雷达处理
        lidar_objects = self.perception.process_lidar(sensor_data['lidar'])
        
        # 融合
        fused_objects = self.perception.fuse_detections(
            [objects, radar_objects, lidar_objects]
        )
        
        return fused_objects
    
    def prediction_step(self, objects, hd_map):
        """预测步骤 - 预测其他交通参与者的轨迹"""
        trajectories = {}
        
        for obj in objects:
            # 短期预测 (3秒)
            short_term = self.prediction.predict_short_term(
                obj, 
                horizon=3.0
            )
            
            # 长期预测
            long_term = self.prediction.predict_long_term(
                obj,
                hd_map,
                horizon=8.0
            )
            
            trajectories[obj.id] = {
                'short_term': short_term,
                'long_term': long_term,
            }
            
        return trajectories
    
    def planning_step(self, ego_state, objects, trajectories, hd_map):
        """规划步骤"""
        # 行为规划
        behavior = self.planning.behavior_planning(
            ego_state, 
            objects,
            trajectories
        )
        
        # 运动规划
        trajectory = self.planning.motion_planning(
            ego_state,
            behavior,
            hd_map
        )
        
        # 速度规划
        speed_profile = self.planning.speed_planning(trajectory)
        
        return {
            'behavior': behavior,
            'trajectory': trajectory,
            'speed_profile': speed_profile,
        }
    
    def control_step(self, plan, ego_state):
        """控制步骤"""
        # 横向控制 (LQR)
        lateral_cmd = self.control.lateral_control(
            plan['trajectory'],
            ego_state
        )
        
        # 纵向控制 (PID)
        longitudinal_cmd = self.control.longitudinal_control(
            plan['speed_profile'],
            ego_state.velocity
        )
        
        return {
            'steering': lateral_cmd,
            'throttle': longitudinal_cmd['throttle'],
            'brake': longitudinal_cmd['brake'],
        }
```

---

## 4. 初创公司

### 4.1 Physical Intelligence

- π0模型
- 流体动作

### 4.2 Covariant

- RFUniverse
- 多模态AI

### 4.3 π0 模型推理示例

```python
class PiZeroInference:
    """π0 模型推理接口"""
    
    def __init__(self, model_path="pi0_base.pt"):
        self.model = torch.jit.load(model_path)
        self.model.eval()
        
        # 图像预处理器
        self.image_processor = AutoImageProcessor.from_pretrained(
            "google/siglip-so-400m-patch14-224"
        )
        
    @torch.no_grad()
    def predict(self, images, instruction, state=None):
        """
        π0 动作预测
        
        Args:
            images: 机器人视角图像 (B, T, C, H, W)
            instruction: 语言指令 string
            state: 关节状态 (B, 14)
        """
        # 预处理图像
        processed_images = []
        for img in images:
            processed = self.image_processor(img)
            processed_images.append(processed)
        
        image_tensor = torch.stack(processed_images)
        
        # 编码指令
        instruction_ids = self.tokenizer(instruction)
        
        # 推理
        action = self.model(
            image_tensor=image_tensor,
            instruction_ids=instruction_ids,
            state=state,
        )
        
        return action
    
    def stream_action(self, image, instruction, state):
        """流式推理 - 实时控制"""
        image_buffer = []
        
        while True:
            # 收集最近T帧
            image_buffer.append(image)
            if len(image_buffer) > self.window_size:
                image_buffer.pop(0)
                
            # 预测动作
            action = self.predict(
                images=image_buffer,
                instruction=instruction,
                state=state
            )
            
            yield action
```

---

## 5. 最新产品对比

### 5.1 人形机器人对比

| 型号 | 自由度 | 身高 | 重量 | 续航 | 价格 |
|------|--------|------|------|------|------|
| Figure 02 | 42 | 170cm | 70kg | 5h | $ |
| Unitree G1 | 43 | 167cm | 35kg | 2h | $$ |
| Atlas | 28 | 150cm | 89kg | 1h | $$$$ |
| Tesla Optimus | 40+ | 172cm | 57kg | TBD | TBD |

### 5.2 仿真平台对比

| 平台 | 渲染引擎 | 物理引擎 | 实时性 | 成本 |
|------|----------|----------|--------|------|
| Isaac Sim | RTX | PhysX | ★★★★★ | $ |
| Gazebo | Ogre | ODE/Bullet | ★★★★ | 免费 |
| PyBullet | OpenGL | Bullet | ★★★ | 免费 |
| SAPIEN | CUDA | PhysX | ★★★★ | $$ |

---

*本章节持续更新中...*
