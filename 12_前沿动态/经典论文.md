# 经典论文

Physical AI/具身智能领域的奠基性论文与技术里程碑。

## 目录

- [1. 强化学习基础](#1-强化学习基础)
- [2. 模仿学习](#2-模仿学习)
- [3. 深度感知与计算机视觉](#3-深度感知与计算机视觉)
- [4. 机器人Transformer](#4-机器人transformer)
- [5. 扩散模型与生成式方法](#5-扩散模型与生成式方法)
- [6. 具身智能基准](#6-具身智能基准)

---

## 1. 强化学习基础

### 1.1 DQN (Deep Q-Network)

| 项目 | 内容 |
|------|------|
| **论文** | Human-level control through deep reinforcement learning |
| **作者** | Mnih et al. |
| **机构** | DeepMind |
| **年份** | 2015 (Nature) |
| **arXiv** | [1312.5602](https://arxiv.org/abs/1312.5602) |

**核心贡献**：
- 首次将深度学习与强化学习结合
- 提出经验回放(Experience Replay)机制
- 引入目标网络(Target Network)稳定训练

**意义**：开启了深度强化学习时代，为后续机器人RL奠定基础。

---

### 1.2 PPO (Proximal Policy Optimization)

| 项目 | 内容 |
|------|------|
| **论文** | Proximal Policy Optimization Algorithms |
| **作者** | Schulman et al. |
| **机构** | OpenAI |
| **年份** | 2017 |
| **arXiv** | [1707.06347](https://arxiv.org/abs/1707.06347) |

**核心贡献**：
- 提出置信域策略梯度优化(TRPO)的简化版本
- 引入裁剪(Clipping)机制防止策略剧烈变化
- 实现简单、数据效率高、泛化能力强

**意义**：目前机器人领域最广泛使用的RL算法之一。

---

### 1.3 SAC (Soft Actor-Critic)

| 项目 | 内容 |
|------|------|
| **论文** | Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor |
| **作者** | Haarnoja et al. |
| **机构** | Berkeley BAIR |
| **年份** | 2018 |
| **arXiv** | [1801.01290](https://arxiv.org/abs/1801.01290) |

**核心贡献**：
- 引入最大熵框架提高探索和稳定性
- 离策略(Off-Policy)算法，数据效率高
- 自动温度参数调节

**意义**：在连续控制任务中表现优异，广泛应用于机器人操纵。

---

### 1.4 QT-Opt

| 项目 | 内容 |
|------|------|
| **论文** | QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation |
| **作者** | Kalashnikov et al. |
| **机构** | Google DeepMind |
| **年份** | 2018 |
| **arXiv** | [1806.10293](https://arxiv.org/abs/1806.10293) |

**核心贡献**：
- 分布式RL训练框架
- 基于视觉的抓取任务
- 7个真实机器人协同收集数据

**意义**：首次大规模展示深度RL在真实机器人上的可行性。

---

## 2. 模仿学习

### 2.1 DAgger

| 项目 | 内容 |
|------|------|
| **论文** | A Reduction of Imitation Learning to No-Regret Online Learning |
| **作者** | Ross et al. |
| **机构** | CMU |
| **年份** | 2011 |
| **arXiv** | - |

**核心贡献**：
- 提出迭代学习策略消除累积误差
- 理论基础：no-regret在线学习
- 核心思想：专家数据+自身策略数据混合训练

**意义**：奠定了模仿学习理论基础，是BC升级版的标准方法。

---

### 2.2 GAIL (Generative Adversarial Imitation Learning)

| 项目 | 内容 |
|------|------|
| **论文** | Generative Adversarial Imitation Learning |
| **作者** | Ho & Ermon |
| **机构** | Stanford |
| **年份** | 2016 |
| **arXiv** | [1606.03476](https://arxiv.org/abs/1606.03476) |

**核心贡献**：
- 引入GAN思想到模仿学习
- 鉴别器区分专家轨迹与策略轨迹
- 无需显式奖励函数

**意义**：连接了IRL与深度学习，推动模仿学习发展。

---

### 2.3 Behavior Cloning (早期工作)

| 项目 | 内容 |
|------|------|
| **论文** | ALVINN: An Autonomous Land Vehicle In a Neural Network |
| **作者** | Pomerleau |
| **机构** | CMU |
| **年份** | 1989 |

**核心贡献**：
- 最早的神经网络模仿学习实例
- 端到端学习驾驶策略

**意义**：模仿学习的开山之作，展示了从专家演示学习的能力。

---

## 3. 深度感知与计算机视觉

### 3.1 ResNet

| 项目 | 内容 |
|------|------|
| **论文** | Deep Residual Learning for Image Recognition |
| **作者** | He et al. |
| **机构** | Microsoft Research |
| **年份** | 2015 |
| **arXiv** | [1512.03385](https://arxiv.org/abs/1512.03385) |

**核心贡献**：
- 残差连接解决深层网络梯度消失问题
- ImageNet 152层深度网络
- 计算机视觉基础 backbone

**意义**：视觉感知的基础架构，机器人视觉的标配。

---

### 3.2 Mask R-CNN

| 项目 | 内容 |
|------|------|
| **论文** | Mask R-CNN |
| **作者** | He et al. |
| **机构** | Facebook AI |
| **年份** | 2017 |
| **arXiv** | [1703.06870](https://arxiv.org/abs/1703.06870) |

**核心贡献**：
- 实例分割框架
- RoI Align 替代 RoI Pooling
- 同时检测、分割、姿态估计

**意义**：机器人抓取感知的重要基础。

---

## 4. 机器人Transformer

### 4.1 RT-1 (Robotics Transformer)

| 项目 | 内容 |
|------|------|
| **论文** | RT-1: Robotics Transformer for Real-World Control at Scale |
| **作者** | Brohan et al. |
| **机构** | Google DeepMind |
| **年份** | 2022 |
| **arXiv** | [2212.06817](https://arxiv.org/abs/2212.06817) |

**核心贡献**：
- 首个大规模视觉语言动作模型(VLA)
- 13万条机器人轨迹训练
- 展示泛化能力与可扩展性

**意义**：开启机器人Transformer时代。

---

### 4.2 RT-2

| 项目 | 内容 |
|------|------|
| **论文** | RT-2: Vision-Language-Action Models |
| **作者** | Brohan et al. |
| **机构** | Google DeepMind |
| **年份** | 2023 |
| **arXiv** | [2307.15818](https://arxiv.org/abs/2307.15818) |

**核心贡献**：
- 预训练VLM直接输出动作
- 符号理解、推理能力迁移到机器人
- 泛化能力显著提升

**意义**：展示了互联网规模预训练对机器人学习的价值。

---

### 4.3 RT-X

| 项目 | 内容 |
|------|------|
| **论文** | Open X-Embodiment: Robotic Learning Datasets and RT-X |
| **作者** | Padalkar et al. |
| **机构** | Google DeepMind + 30+机构 |
| **年份** | 2023 |
| **arXiv** | [2310.08864](https://arxiv.org/abs/2310.08864) |

**核心贡献**：
- 整合30+机构数据，100万条轨迹
- 跨实体泛化学习
- 开源数据集+模型

**意义**：具身智能数据标准化的里程碑。

---

### 4.4 PALM-E

| 项目 | 内容 |
|------|------|
| **论文** | PALM-E: An Embodied Multimodal Language Model |
| **作者** | Driess et al. |
| **机构** | Google DeepMind |
| **年份** | 2023 |
| **arXiv** | [2303.03372](https://arxiv.org/abs/2303.03372) |

**核心贡献**：
- 5620亿参数大模型
- 视觉编码器+语言模型+机器人状态
- 零-shot推理与规划

**意义**：展示多模态大模型理解物理世界的潜力。

---

### 4.5 VoxPoser

| 项目 | 内容 |
|------|------|
| **论文** | VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models |
| **作者** | Zhou et al. |
| **机构** | Stanford |
| **年份** | 2023 |
| **arXiv** | [2307.05973](https://arxiv.org/abs/2307.05973) |

**核心贡献**：
- LLM生成3D价值图
- 组合式任务泛化
- 无需额外训练

**意义**：LLM+机器人规划的新范式。

---

## 5. 扩散模型与生成式方法

### 5.1 Diffusion Policy

| 项目 | 内容 |
|------|------|
| **论文** | Diffusion Policy: Visuomotor Policy Learning via Action Diffusion |
| **作者** | Chi et al. |
| **机构** | Columbia, Toyota Research |
| **年份** | 2024 (RSS) |
| **arXiv** | [2303.04137](https://arxiv.org/abs/2303.04137) |

**核心贡献**：
- 将动作建模为扩散过程
- 相比LSTM/Transformer策略显著提升
- 展示高维动作空间的建模能力

**意义**：扩散模型应用于机器人操作的开创性工作。

---

### 5.2 ACT (Action Chunking Transformer)

| 项目 | 内容 |
|------|------|
| **论文** | Learning to Generate Conservative Progressively and Imitate Flexibly |
| **作者** | Zhao et al. |
| **机构** | Stanford |
| **年份** | 2024 |
| **GitHub** | [ACT](https://github.com/tonylzq/ALOHA) |

**核心贡献**：
- 动作分块处理时序依赖
- Transformer架构
- ALOHA硬件配套论文

**意义**：低成本模仿学习硬件+算法方案。

---

### 5.3 RDT (Rechastic Diffusion Transformer)

| 项目 | 内容 |
|------|------|
| **论文** | RDT: Robust Diffusion Transformer for Manipulation |
| **作者** | Lin et al. |
| **机构** | 清华大学等 |
| **年份** | 2024 |

**核心贡献**：
- 将扩散模型与Transformer结合
- 增强泛化与鲁棒性
- 10亿参数级别模型

**意义**：大模型级别的扩散策略。

---

## 6. 具身智能基准

### 6.1 RLBench

| 项目 | 内容 |
|------|------|
| **论文** | RLBench: The Robot Learning Benchmark and Learning Environment |
| **作者** | James et al. |
| **机构** | Imperial College London |
| **年份** | 2020 |
| **arXiv** | [2006.12983](https://arxiv.org/abs/2006.12983) |

**核心贡献**：
- 标准化机器人学习基准
- 100+任务定义
- 统一的评估协议

**意义**：推动机器人学习研究标准化。

---

### 6.2 Meta-World

| 项目 | 内容 |
|------|------|
| **论文** | Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning |
| **作者** | Yu et al. |
| **机构** | UC Berkeley |
| **年份** | 2019 |
| **arXiv** | [1910.10897](https://arxiv.org/abs/1910.10897) |

**核心贡献**：
- 多任务强化学习基准
- 50个不同机器人操作任务
- 任务变异性高

**意义**：推动元学习和多任务学习研究。

---

### 6.3 SAPIEN

| 项目 | 内容 |
|------|------|
| **论文** | SAPIEN: A SimulAted Part-based Interactive ENvironment |
| **作者** | Geng et al. |
| **机构** | Stanford, NVIDIA |
| **年份** | 2020 |
| **arXiv** | [2003.08515](https://arxiv.org/abs/2003.08515) |

**核心贡献**：
- 物理逼真的交互环境
- 基于部件的物体表示
- 支持大规模数据生成

**意义**：高质量机器人仿真环境。

---

## 阅读建议

### 入门路线
1. **强化学习基础**: DQN → PPO → SAC
2. **模仿学习**: BC → DAgger → GAIL
3. **深度视觉**: ResNet → Mask R-CNN
4. **机器人Transformers**: RT-1 → RT-2 → RT-X

### 进阶路线
1. **扩散策略**: Diffusion Policy
2. **LLM+机器人**: VoxPoser, PALM-E
3. **最新VLA**: RT-4, OpenVLA, π0

### 必读经典
- **RL**: PPO, SAC
- **Imitation Learning**: DAgger, GAIL
- **Robot Learning**: QT-Opt, RT-X
- **Diffusion**: Diffusion Policy

---

*本章节持续更新中，欢迎提交PR补充更多经典论文。*
